{
    "collab_server" : "",
    "contents" : "source('modules/Classes/Transition.R')\nsource('modules/Classes/PayoffFunction.R')\n\nDPEngine <- \n  setRefClass(\n    'DPEngine',\n    fields = list(\n      iter.stop.threshold = 'numeric',\n      beta = 'numeric',\n      num.states = 'numeric',\n      num.actions = 'numeric',\n      num.theta = 'numeric',\n      dirichlet.alpha = 'numeric',\n      tran = 'Transition',\n      payoff = 'PayoffFunction',\n      CCP = 'list',\n      CCP.saved = 'list', #Last \"saved\" CCPs\n      value.fn = 'numeric',\n      policy.iteration.mat = 'matrix'\n    ),\n    methods = list(\n      initializeDP = function(){\n        iter.stop.threshold <<- 10^-10\n        \n        tran <<-\n          Transition$new(\n            num.states = num.states,\n            num.actions = num.actions,\n            dirichlet.alpha = dirichlet.alpha) %T>% {\n              .$calc_transition()\n            }\n        \n        payoff <<-\n          PayoffFunction$new() %T>% {\n            .$createPayoffStats(num.states, num.actions, num.theta)\n          }\n        \n        resetSystem()\n      },\n      \n      updateValues_VI = function(){\n        #Maps CCPs and values to values\n        value.fn <<-\n          list(\n            CCP,\n            payoff$utility,\n            tran$tran.mat\n          ) %>%\n          pmap(function(ccp, payoff, mat){\n            ccp * (payoff - log(ccp) + beta * mat %*% value.fn)\n          }) %>%\n          Reduce('+', .) %>% \n          c\n      },\n      \n      updateValues_PI = function(){\n        #Maps CCPs and payoffs to values\n        value.fn <<-\n          map2(\n            CCP,\n            payoff$utility,\n            ~ .x * (.y - log(.x))\n          ) %>%\n          Reduce('+', .) %>% {\n            policy.iteration.mat %*% .\n          } %>%\n          c\n      },\n      \n      updateCCPs = function(){\n        #Maps values to CCPs\n        CCP <<- \n          map2(\n            payoff$utility,\n            tran$tran.mat,\n            ~ .x + beta * .y %*% value.fn\n          ) %>% {\n            max.CSV <- Reduce(pmax, .) \n            map(., ~ . - max.CSV)\n          } %>%\n          map(~ exp(.)) %>% {\n            denominator <-\n              Reduce('+', .)\n            map(., ~ c(./denominator))\n          } %>%\n          map(~ pmax(10^-100, .))\n      },\n      \n      operator_VI = function(){\n        updateCCPs()\n        updateValues_VI()\n      },\n      \n      operator_PI = function(){\n        updateValues_PI()\n        updateCCPs()\n      },\n      \n      calcPolicyIterationMat = function(){\n        policy.iteration.mat <<-\n          map2(\n            CCP,\n            tran$tran.mat,\n            ~ .x * .y\n          ) %>%\n          Reduce('+', .) %>% {\n            solve(diag(ncol(.)) - beta * .)\n          } \n      },\n      \n      estimateInitialCCPs = function(panel) {\n        CCP <<-\n          seq(payoff$payoff.stat) %>%\n          ld(function(l){\n            payoff$payoff.stat[[l]] %>%\n              ad %>%\n              mt(\n                action = l,\n                state = row_number()\n              ) %>%\n              ml(c('action', 'state'), variable.name = 'stat')\n          }) %>% \n          dc(state ~ stat + action) %>% {\n            new.data <- .\n            my.formula <- \n              sl(., -state) %>% \n              names %>%\n              paste(collapse = '+') %>% {\n                paste('action', ., sep = '~')\n              } %>% \n              as.formula\n            \n            ij(., panel) %>%\n              nnet::multinom(\n                my.formula,\n                data = .,\n                weights = n\n              ) %>%\n              predict(., type = 'probs', newdata = new.data) \n          } %>% {\n            if(class(.) == 'matrix') {\n              alply(., 2, function(l) l)\n            } else {\n              list(1 - ., .)\n            }\n          }\n          \n      },\n      \n      calcDP_policy = function(theta){\n        payoff$updatePayoffs(theta)\n        delta <- 1\n        print(h(value.fn))\n        while(delta > iter.stop.threshold){\n          print('value iteration')\n          CCP.prior <- CCP\n          operator_VI()\n          delta <-\n            map2(\n              CCP.prior,\n              CCP,\n              ~ max(abs(.x - .y))\n            ) %>%\n            rd(max)\n        }\n      },\n      \n      calcDP_value = function(theta){\n        #Rust's method for finding value function: value interations then Newton steps\n        payoff$updatePayoffs(theta)\n        delta.prior <- 0\n        delta <- 1\n        newton <- FALSE\n        newton.iterations <- 0 \n        while(delta > iter.stop.threshold){\n          value.fn.prior <- value.fn\n          if(newton) {\n            print('Newton policy iteration')\n            newton.iterations <- newton.iterations + 1\n            calcPolicyIterationMat()\n            operator_PI()\n          } else {\n            print('Newton value iteration')\n            operator_VI()\n          }\n          print(delta)\n          delta <- max(abs(value.fn.prior - value.fn))\n          if((delta < 10^-3) & (abs(delta/delta.prior - beta) < 10^-4)) newton <- TRUE\n          if(newton.iterations == 3) delta <- 0 #Avoid infinite loops due to lack of precision\n          delta.prior <- delta\n        }\n      },\n      \n      resetSystem = function(){\n        value.fn <<- rep(0, num.states)\n        CCP <<- #set all CCPs  1/num.actions\n          seq(num.actions) %>%\n          map(~ rep(1/num.actions, num.states))\n        saveCCPs()\n      },\n      \n      saveCCPs = function(){\n        CCP.saved <<- CCP\n      },\n      \n      loadCCPs = function(){\n        CCP <<- CCP.saved\n      }\n    )\n  )\n",
    "created" : 1457553524456.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "143901399",
    "id" : "BA21D77",
    "lastKnownWriteTime" : 1457900131,
    "last_content_update" : 1457900131381,
    "path" : "~/Dropbox/code/victor/code/modules/Classes/DPEngine.R",
    "project_path" : "modules/Classes/DPEngine.R",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}